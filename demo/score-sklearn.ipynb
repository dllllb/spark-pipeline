{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup:\n",
    "!conda install pyspark openjdk scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "os.environ['PYTHONPATH'] = os.path.realpath('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(f'titanic.csv')\n",
    "features = ds.drop(['survived', 'alive'], axis=1)\n",
    "features = features.replace(r'\\\\s+', np.nan, regex=True)\n",
    "features = pd.get_dummies(features)\n",
    "features = features.fillna(features.mean())\n",
    "target = ds.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "f_t, f_v, t_t, t_v = train_test_split(features, target, test_size=0.5)\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=10).fit(f_t, t_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      label  target_proba\n0  positive           1.0\n1  positive           0.3\n2  positive           0.5\n3  positive           0.8\n4  positive           1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>target_proba</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>positive</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>positive</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>positive</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>positive</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = ss.createDataFrame(f_v)\n",
    "\n",
    "from sparktools.core import score\n",
    "\n",
    "score_df = score(sc=ss.sparkContext, sdf=df, model=m).cache()\n",
    "\n",
    "scores = score_df.toPandas()\n",
    "\n",
    "scores.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}